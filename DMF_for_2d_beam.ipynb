{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "device = 'cuda:2'\n",
    "import torch\n",
    "import numpy as np\n",
    "# Set random seeds for reproducibility\n",
    "#torch.manual_seed(1)\n",
    "#np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problems():\n",
    "    def dlX_disp(self):\n",
    "        domain_xcoord = np.random.uniform(-self.nelx/(2*(self.nelm)),self.nelx/(2*(self.nelm)),(self.batch_size - self.dlX_fixed.shape[0] - self.dlX_force.shape[0],1))\n",
    "        domain_ycoord = np.random.uniform(-self.nely/(2*(self.nelm)),self.nely/(2*(self.nelm)),(self.batch_size - self.dlX_fixed.shape[0] - self.dlX_force.shape[0],1))\n",
    "        domain_coord = np.concatenate((domain_ycoord,domain_xcoord),axis = 1)\n",
    "        coord = np.concatenate((self.dlX_fixed.cpu().detach().numpy(), self.dlX_force.cpu().detach().numpy()),axis = 0)\n",
    "        coord = np.concatenate((coord, domain_coord),axis = 0)\n",
    "        coord = torch.tensor(coord,dtype=torch.float32,requires_grad=True).to(device)\n",
    "        return coord\n",
    "\n",
    "class Cantilever_Beam_2D(Problems):\n",
    "    def __init__(self, nelx, nely, xid, yid, vf):\n",
    "\n",
    "        # Initialize geometry parameters\n",
    "        self.xid = xid\n",
    "        self.yid = yid\n",
    "        self.nelx = nelx\n",
    "        self.nely = nely\n",
    "        self.nele = self.nelx*self.nely\n",
    "        self.nelm = max(self.nelx,self.nely)\n",
    "        self.volfrac = vf\n",
    "        self.E0 = 1\n",
    "        self.nu = 0.3\n",
    "        \n",
    "        self.batch_size = 25000\n",
    "\n",
    "        self.alpha_init = 1\n",
    "        self.alpha_max = 100\n",
    "        self.alpha_delta = 0.5\n",
    "        self.penal = 3.0\n",
    "        \n",
    "        c_y, c_x=np.meshgrid(np.linspace(-(self.nely)/(2*self.nelm),(self.nely)/(2*self.nelm),self.nely),\n",
    "                                                np.linspace(-(self.nelx)/(2*self.nelm),(self.nelx)/(2*self.nelm),self.nelx)\n",
    "                                                ,indexing='ij')\n",
    "        self.dlX = np.stack((c_y.reshape([-1]),c_x.reshape([-1])),axis = 1).reshape([-1,2])\n",
    "        c_y, c_x=np.meshgrid(np.linspace(-(self.nely)/(2*self.nelm),(self.nely)/(2*self.nelm),2*self.nely),\n",
    "                                                np.linspace(-(self.nelx)/(2*self.nelm),(self.nelx)/(2*self.nelm),2*self.nelx)\n",
    "                                                ,indexing='ij')\n",
    "        self.dlXSS = np.stack((c_y.reshape([-1]),c_x.reshape([-1])),axis = 1).reshape([-1,2])\n",
    "        self.V = (np.max(self.dlX[:,0])-np.min(self.dlX[:,0]))*(np.max(self.dlX[:,1])-np.min(self.dlX[:,1]))\n",
    "\n",
    "        #Problem boundary condition\n",
    "        fixed_voxel = np.zeros((self.nely,self.nelx))\n",
    "        fixed_voxel[:,0] = 1.0\n",
    "        fixed_voxel = fixed_voxel.reshape([self.nele,1])\n",
    "        dlX_fixed = self.dlX[np.where(fixed_voxel == 1.0)[0],:]\n",
    "\n",
    "        F = 0.1\n",
    "        self.F_vector = torch.tensor([[F], [0.0]], dtype=torch.float32).to(device)\n",
    "        self.force_voxel = np.zeros((self.nely,self.nelx)) \n",
    "        self.force_voxel[yid,xid] = 1\n",
    "        force_voxel = self.force_voxel.reshape([self.nele,1])\n",
    "        dlX_force = self.dlX[np.where(force_voxel == 1)[0],:]\n",
    "\n",
    "        self.dlX = torch.tensor(self.dlX, dtype=torch.float32,requires_grad=True).to(device)\n",
    "        self.dlXSS = torch.tensor(self.dlXSS, dtype=torch.float32,requires_grad=True).to(device)\n",
    "        self.dlX_fixed = torch.tensor(dlX_fixed, dtype=torch.float32,requires_grad=True).to(device)\n",
    "        self.dlX_force = torch.tensor(dlX_force, dtype=torch.float32,requires_grad=True).to(device)\n",
    "\n",
    "    def analytical_fixed_BC(self,u,coord):\n",
    "        u = u*2*(1/(1+torch.exp(-20*(coord[:,1:2]+0.5))) - 0.5)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN():\n",
    "    def __init__(self, problem, disp_model):\n",
    "        self.problem = problem\n",
    "        self.disp_model = disp_model\n",
    "  \n",
    "    def pinn_loss(self,xPhys_m, coord):\n",
    "        u = self.disp_model(coord)\n",
    "        u = self.problem.analytical_fixed_BC(u,coord)\n",
    "\n",
    "        u1 = u[:,0:1]\n",
    "        u0 = u[:,1:2]\n",
    "        uy_xyz = torch.autograd.grad(outputs=u1, inputs=coord,\n",
    "                                        grad_outputs=torch.ones_like(u1),\n",
    "                                        create_graph = True, retain_graph = True)[0]\n",
    "        ux_xyz = torch.autograd.grad(outputs=u0, inputs=coord,\n",
    "                                        grad_outputs=torch.ones_like(u0),\n",
    "                                        create_graph = True, retain_graph = True)[0]\n",
    "                                        \n",
    "        eps11 = ux_xyz[:,1]\n",
    "        eps12 = 0.5 * ux_xyz[:,0] + 0.5 * uy_xyz[:,1]\n",
    "        eps22 = uy_xyz[:,0]\n",
    "\n",
    "        youngs_modulus = 1000\n",
    "        poissons_ratio = 0.3\n",
    "        lame_mu = youngs_modulus / (2.0 * (1.0 + poissons_ratio))\n",
    "        lame_lambda = youngs_modulus * poissons_ratio / (1.0 - poissons_ratio**2)\n",
    "        trace_strain = eps11 + eps22\n",
    "        squared_diagonal = eps11 * eps11 + eps22 * eps22\n",
    "        energy = 0.5 * lame_lambda * trace_strain * trace_strain + lame_mu * (squared_diagonal + 2.0 * eps12 * eps12)\n",
    "        energy = energy.reshape(-1,1)*(xPhys_m**3.0)\n",
    "        energy_c = energy\n",
    "        energy_ans = self.problem.V*torch.mean(energy)\n",
    "        force_l = torch.mean(torch.matmul(self.disp_model(self.problem.dlX_force),self.problem.F_vector))\n",
    "        loss = (energy_ans - force_l)\n",
    "        return loss, energy_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class TO_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TO_Net, self).__init__()\n",
    "        low_band = 0.0\n",
    "        high_band = 35\n",
    "        c_y, c_x=np.meshgrid(np.linspace([-high_band,low_band],[-low_band,high_band],10).reshape([-1]),\n",
    "                                                    np.linspace([-high_band,low_band],[-low_band,high_band],10).reshape([-1])\n",
    "                                                    ,indexing='ij')\n",
    "        self.kernel1 = torch.tensor(np.stack((c_y.reshape([-1]),c_x.reshape([-1])),axis = 0),dtype=torch.float32).to(device)\n",
    "        self.kernel1 = torch.nn.Parameter(self.kernel1.requires_grad_())\n",
    "        self.weights1 = torch.zeros([self.kernel1.shape[1],1],dtype=torch.float32).to(device)\n",
    "        self.weights1 = torch.nn.Parameter(self.weights1.requires_grad_())\n",
    "            \n",
    "    def forward(self, x):\n",
    "        y = torch.sin(torch.matmul(x,1.0* self.kernel1 ) + torch.ones([1,self.kernel1.shape[1]]).to(device))\n",
    "        y = torch.sigmoid(torch.matmul(y, self.weights1))\n",
    "        return y\n",
    "    \n",
    "class Disp_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Disp_Net, self).__init__()\n",
    "        low_band = 0.0\n",
    "        high_band = 35\n",
    "        c_y, c_x=np.meshgrid(np.linspace([-high_band,low_band],[-low_band,high_band],10).reshape([-1]),\n",
    "                                                    np.linspace([-high_band,low_band],[-low_band,high_band],10).reshape([-1]),\n",
    "                                                    indexing='ij')\n",
    "        self.kernel1 = torch.tensor(np.stack((c_y.reshape([-1]),c_x.reshape([-1])),axis = 0),dtype=torch.float32).to(device)\n",
    "        self.kernel1 = torch.nn.Parameter(self.kernel1.requires_grad_())\n",
    "        self.weights1 = torch.zeros([self.kernel1.shape[1],2],dtype=torch.float32).to(device)\n",
    "        self.weights1 = torch.nn.Parameter(self.weights1.requires_grad_())\n",
    "    def forward(self, x):\n",
    "        y = torch.sin(torch.matmul(x,1.0* self.kernel1 ) + torch.ones([1,self.kernel1.shape[1]]).to(device))\n",
    "        y = torch.matmul(y, self.weights1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import torch.profiler\n",
    "\n",
    "\n",
    "class DMF_TONN():\n",
    "\n",
    "    def __init__(self, problem, to_model, disp_model):\n",
    "        self.problem = problem\n",
    "        self.disp_model = disp_model\n",
    "        self.to_model = to_model\n",
    "        self.log_vf = []\n",
    "        self.log_disp_loss = []\n",
    "        self.log_c = []\n",
    "        self.log_pinn_init_loss = []\n",
    "        self.log_fec = []\n",
    "        self.log_xPhys = []\n",
    "        self.pinn = PINN(self.problem, self.disp_model)\n",
    "        self.total_epoch = 0\n",
    "\n",
    "        self.disp_optimizer = optim.Adam(self.disp_model.parameters(), lr=0.000005)\n",
    "        self.to_optimizer = optim.Adam(self.to_model.parameters(), lr=0.002)\n",
    "        #self.coord = problem.dlX_disp()\n",
    "    '''\n",
    "    def train_step_disp(self, xPhys_m, coord):\n",
    "        loss, _ = self.pinn.pinn_loss(xPhys_m, coord)\n",
    "        self.log_pinn_init_loss.append(loss.item())\n",
    "        self.disp_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.disp_optimizer.step()\n",
    "'''\n",
    "    def fit_disp_init(self):\n",
    "        epochs = 1000\n",
    "        for epoch in range(epochs):\n",
    "            if epoch % 100 == 1:\n",
    "                display.clear_output(wait=True)\n",
    "\n",
    "            coord = self.problem.dlX_disp()\n",
    "            xPhys = torch.ones(coord.shape[0], 1) * 0.5\n",
    "            loss, energy_c = self.pinn.pinn_loss(xPhys.to(device), coord)\n",
    "            self.log_pinn_init_loss.append(loss.item())\n",
    "            self.disp_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.disp_optimizer.step()\n",
    "\n",
    "        xPhys = torch.ones(self.problem.dlX.shape[0], 1) * 0.5\n",
    "        loss, energy_c = self.pinn.pinn_loss(xPhys.to(device), self.problem.dlX)\n",
    "        self.c1 = energy_c\n",
    "        self.c_0 = torch.mean(energy_c)\n",
    "\n",
    "    def to_loss(self, coord):\n",
    "        self.total_epoch = self.total_epoch+1\n",
    "        xPhys_m = self.to_model(coord)\n",
    "        alpha = min(self.problem.alpha_init + self.problem.alpha_delta * self.total_epoch, self.problem.alpha_max)\n",
    "        _, energy_c = self.pinn.pinn_loss(xPhys_m, coord)\n",
    "        class ComputeDeDrho(torch.autograd.Function):\n",
    "            @staticmethod\n",
    "            def forward(ctx, xPhys_m, energy_c, coord):\n",
    "                # 将必要的模型信息保存到上下文中，以便反向传播时使用\n",
    "\n",
    "                ctx.xPhys_m = xPhys_m\n",
    "                ctx.coord = coord\n",
    "                \n",
    "                # 正向传播部分：计算能量\n",
    "                #loss, energy_c = opt.pinn.pinn_loss(xPhys_m, coord)\n",
    "                # 返回正向输出\n",
    "                ctx.save_for_backward(xPhys_m,energy_c,coord)\n",
    "                return energy_c\n",
    "\n",
    "            @staticmethod\n",
    "            def backward(ctx, denergy):\n",
    "                # 获取正向传播时保存的中间结果\n",
    "                xPhys_m, energy_c, coord = ctx.saved_tensors\n",
    "                \n",
    "                # 计算反向传播梯度\n",
    "                # 使用 torch.autograd.grad 计算能量关于 xPhys_m 的梯度\n",
    "                grad_energy = torch.autograd.grad(\n",
    "                outputs=energy_c, \n",
    "                inputs=xPhys_m, \n",
    "                grad_outputs=denergy, \n",
    "                create_graph=True,  # 支持二阶梯度\n",
    "                retain_graph=True\n",
    "                )[0]\n",
    "                gradients = grad_energy\n",
    "                # 返回负梯度，剩余的输入梯度为零\n",
    "                return -gradients, torch.zeros_like(energy_c), torch.zeros_like(coord)\n",
    "        c = torch.mean(ComputeDeDrho.apply(xPhys_m, energy_c, coord))\n",
    "        xPhys_dlX = self.to_model(self.problem.dlX)\n",
    "        vf = torch.mean(xPhys_dlX)\n",
    "        loss =  alpha*(vf / self.problem.volfrac - 1.0) ** 2 + 1 * c / self.c_0.detach() \n",
    "        print('Epoch:', self.total_epoch)\n",
    "        print('Total Loss:', loss.item())\n",
    "        print(\"c\",c.item())\n",
    "        self.log_c.append(c.item())\n",
    "        self.log_vf.append(vf.item())\n",
    "        self.log_xPhys.append(xPhys_dlX.detach())\n",
    "        return loss\n",
    "\n",
    "    def fit_disp(self, epochs=200):\n",
    "        for i in range(epochs):\n",
    "            coord = self.problem.dlX_disp()\n",
    "            xPhys_m = self.to_model(coord)\n",
    "            loss, _ = self.pinn.pinn_loss(xPhys_m, coord)\n",
    "            self.log_disp_loss.append(loss.item())\n",
    "            self.disp_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.disp_optimizer.step()\n",
    "    '''\n",
    "    def fit_to(self, epochs):\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            with torch.profiler.profile(\n",
    "            activities=[\n",
    "                torch.profiler.ProfilerActivity.CPU,\n",
    "                torch.profiler.ProfilerActivity.CUDA  # 如果有GPU\n",
    "            ],\n",
    "            record_shapes=True,\n",
    "            profile_memory=True,\n",
    "            with_flops=True,\n",
    "            with_stack=False\n",
    "        ) as prof:\n",
    "                self.fit_disp(50)\n",
    "                if epoch % 10 == 1:\n",
    "                    display.clear_output(wait=True)\n",
    "                coord = self.problem.dlX_disp()\n",
    "                loss = self.to_loss(coord)\n",
    "                self.to_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.to_optimizer.step()\n",
    "            print(prof.key_averages().table(\n",
    "    sort_by=\"flops\",  # 也可以试试 total_flops\n",
    "    row_limit=20\n",
    "))\n",
    "'''\n",
    "           \n",
    "    \n",
    "    def fit_to(self, epochs):\n",
    "        self.time_pde=[]\n",
    "        self.time_density=[]\n",
    "        for epoch in range(epochs):\n",
    "            t1= time.time()\n",
    "            self.fit_disp(50)\n",
    "            t2 = time.time()\n",
    "            self.time_pde.append(t2-t1)\n",
    "            if epoch % 10 == 1:\n",
    "                display.clear_output(wait=True)\n",
    "\n",
    "            coord = self.problem.dlX_disp()\n",
    "            t1= time.time()\n",
    "            loss = self.to_loss(coord)\n",
    "            self.to_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.to_optimizer.step()\n",
    "            t2 = time.time()\n",
    "            self.time_density.append(t2-t1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nelx = 60\n",
    "nely = 20\n",
    "\n",
    "#User defined load location\n",
    "xid = 59\n",
    "yid = 19\n",
    "\n",
    "#User defined target volume fraction\n",
    "vf = 0.3\n",
    "problem= Cantilever_Beam_2D(nelx,nely,xid,yid,vf)\n",
    "to_model= TO_Net().to(device)\n",
    "disp_model_h = Disp_Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = DMF_TONN(problem, to_model, disp_model_h)\n",
    "opt.fit_disp_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 392\n",
      "Total Loss: 0.8536800146102905\n",
      "c 0.0081946961581707\n",
      "Epoch: 393\n",
      "Total Loss: 0.8755147457122803\n",
      "c 0.008412725292146206\n",
      "Epoch: 394\n",
      "Total Loss: 0.8530815839767456\n",
      "c 0.008203857578337193\n",
      "Epoch: 395\n",
      "Total Loss: 0.8625898957252502\n",
      "c 0.008304636925458908\n",
      "Epoch: 396\n",
      "Total Loss: 0.865077018737793\n",
      "c 0.008333859033882618\n",
      "Epoch: 397\n",
      "Total Loss: 0.8557503819465637\n",
      "c 0.008241653442382812\n",
      "Epoch: 398\n",
      "Total Loss: 0.8799347877502441\n",
      "c 0.00846766121685505\n",
      "Epoch: 399\n",
      "Total Loss: 0.8588742017745972\n",
      "c 0.00825289636850357\n",
      "Epoch: 400\n",
      "Total Loss: 0.855959951877594\n",
      "c 0.008221060037612915\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1= time.time()\n",
    "opt.fit_to(400)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xPhys_dlX = opt.to_model(opt.problem.dlXSS.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.reshape(xPhys_dlX.cpu().detach().numpy(),(2*opt.problem.nely,2*opt.problem.nelx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compliance: 0.008203400143686467\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "# 参数设置\n",
    "nelx, nely = 120, 40       # 单元数量\n",
    "E, nu = 1000, 0.3         # 杨氏模量和泊松比\n",
    "rho = 0.5                 # 密度\n",
    "penal = 3.0               # 惩罚因子（此处设为1，即线性）\n",
    "\n",
    "# 平面应力条件下的单元刚度矩阵\n",
    "def lk():\n",
    "    E = 1000\n",
    "    nu = 0.3\n",
    "    k = np.array([1/2 - nu/6, 1/8 + nu/8, -1/4 - nu/12, -1/8 + 3*nu/8,\n",
    "                  -1/4 + nu/12, -1/8 - nu/8, nu/6, 1/8 - 3*nu/8])\n",
    "    KE = E / (1 - nu**2) * np.array([[k[0], k[1], k[2], k[3], k[4], k[5], k[6], k[7]],\n",
    "                                     [k[1], k[0], k[7], k[6], k[5], k[4], k[3], k[2]],\n",
    "                                     [k[2], k[7], k[0], k[5], k[6], k[3], k[4], k[1]],\n",
    "                                     [k[3], k[6], k[5], k[0], k[7], k[2], k[1], k[4]],\n",
    "                                     [k[4], k[5], k[6], k[7], k[0], k[1], k[2], k[3]],\n",
    "                                     [k[5], k[4], k[3], k[2], k[1], k[0], k[7], k[6]],\n",
    "                                     [k[6], k[3], k[4], k[1], k[2], k[7], k[0], k[5]],\n",
    "                                     [k[7], k[2], k[1], k[4], k[3], k[6], k[5], k[0]]])\n",
    "    return KE\n",
    "\n",
    "KE = lk()\n",
    "\n",
    "# 全局自由度编号\n",
    "ndof = 2 * (nelx + 1) * (nely + 1)\n",
    "\n",
    "# 节点编号\n",
    "def node_ids(i, j):\n",
    "    n1 = (nely + 1) * i + j\n",
    "    return np.array([2 * n1, 2 * n1 + 1,\n",
    "                     2 * (n1 + nely + 1), 2 * (n1 + nely + 1) + 1,\n",
    "                     2 * (n1 + nely + 2), 2 * (n1 + nely + 2) + 1,\n",
    "                     2 * (n1 + 1), 2 * (n1 + 1) + 1])\n",
    "\n",
    "# 装配稀疏矩阵结构\n",
    "iK = []\n",
    "jK = []\n",
    "sK = []\n",
    "rho = tt.T[:,::-1]\n",
    "for elx in range(nelx):\n",
    "    for ely in range(nely):\n",
    "        el = elx * nely + ely\n",
    "        nodes = node_ids(elx, ely)\n",
    "        rho_el = rho[elx, ely]\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                iK.append(nodes[i])\n",
    "                jK.append(nodes[j])\n",
    "                sK.append((rho_el ** penal) * KE[i, j])\n",
    "'''\n",
    "for elx in range(nelx):\n",
    "    for ely in range(nely):\n",
    "        el = elx * nely + ely\n",
    "        nodes = node_ids(elx, ely)\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                iK.append(nodes[i])\n",
    "                jK.append(nodes[j])\n",
    "                sK.append((rho ** penal) * KE[i, j])\n",
    "'''\n",
    "# 生成稀疏刚度矩阵\n",
    "K = coo_matrix((sK, (iK, jK)), shape=(ndof, ndof)).tocsc()\n",
    "\n",
    "# 载荷向量\n",
    "F = np.zeros(ndof)\n",
    "# 右下角节点施加载荷\n",
    "frc_node = (nelx) * (nely + 1) + 0\n",
    "F[2 * frc_node + 1] = -0.1  # 垂直向下的力\n",
    "# 右边中间节点施加载荷\n",
    "#mid_j = nely // 2\n",
    "#frc_node = nelx * (nely + 1) + mid_j\n",
    "#F[2 * frc_node + 1] = -0.1  # 垂直向下的力\n",
    "\n",
    "# 边界条件（左边固定）\n",
    "fixeddofs = []\n",
    "for j in range(nely + 1):\n",
    "    n = j\n",
    "    fixeddofs += [2 * n, 2 * n + 1]\n",
    "\n",
    "alldofs = np.arange(ndof)\n",
    "freedofs = np.setdiff1d(alldofs, fixeddofs)\n",
    "\n",
    "# 求解位移\n",
    "U = np.zeros(ndof)\n",
    "K_free = K[freedofs, :][:, freedofs]\n",
    "F_free = F[freedofs]\n",
    "U[freedofs] = spsolve(K_free, F_free)\n",
    "\n",
    "# 计算 compliance\n",
    "compliance = F @ U\n",
    "print(\"Compliance:\", compliance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
